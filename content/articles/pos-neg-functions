---
title: "Tricky Functor instances"
date: 2019-01-13T16:36:32-05:00
draft: false
---

I was recently started reading [Thinking with Types](http://thinkingwithtypes.com/) and came upon a great explanation of variance and the role it plays in reasoning about functions.
You're probably familiar with `Functor`, which says that for some `t a`, if given a function `f :: a -> b`, you can transform the `t a -> t b`. Essentially, the essence of "functor-ness" is the ability to transform a result into another type.
What about "anti-functorn-ness", where you want to transform the input rather than the result of a function from `a -> b`? Is that something interesting and worth exploring?

Indeed it is! The "functor-ness" described above is actually called `Covariance`, and simply means that you can transform the output of some computation `T a`.
Similarly, the "anti-functor-ness" of `T a` is called `Contravariance`, and means that you can transform a `T b` into a `T a` by mapping the input of the computation. There is a third form of variance called `Invariance`, but its not as much fun as co & contra variance.

Type variables in an expression are either positive or negative. In the function `a -> b`, the `b` is positive, while the `a` is negative. Just like integer mathematics, two negatives make a positive, so `(a -> b) -> b` actually has `a` in positive position, meaning this covariant in `a`.
In fact, whether a `T a` is co or contra variant in `a` is determined only by whether `a` is positive or negative. Positive `a` means `Covariance`, while negative `a` means `Contravariance`. If the `a` appears in both positive and negative positions, then its invariant, and therefore not particularly exciting.

I'll extend this in the near future
